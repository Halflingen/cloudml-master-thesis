\mychapter{design}{Analysis and design - CloudML}

In the previous chapter, \citechap{vision}, the core vision of CloudML was presented,
including descriptions of surrounding elements, \eg actors and topologies.
In this chapter the focus is narrowed down to the design and considerations 
of the implementation that constitutes CloudML.

\section{Meta-model}
\input{figs/meta-model}

In this section the meta-model of CloudML will be presented.
The model is visualized in \citefig{meta-model}, and will be described through a specific scenario.
The scenario also describe parts of the implementation design through how it is used.

\paragraph{Scenarios introduction.}

CloudML is introduced by using two different scenarios where a user named ``Alice'' is provisioning the 
\emph{BankManager} application from \citechap{challenges} to the \myac{AWS} cloud.
It is compulsory that she possesses an \myac{AWS} account in advance of the scenario.
This is essential information needed for the scenario to be successful,
and since she is indirectly using \myac{AWS} \myac{API}s,
she must also have \emph{security credentials},
\ie \emph{Access Key ID} and \emph{Secret Access Key}.

The roles assumed by Alice in this scenario, regarding \citefig{big-picture},
are both \emph{cloud expert} and \emph{users}.
She will define the topologies, create the templates and use 
the \emph{engine} to provision her models.
In addition to these roles she is also partly \emph{application designer/developer},
because of tight coupling between running instances and application deployment.

\paragraph{Authentication.}

She associates \emph{Access Key ID} and \emph{Secret Access Key} with 
\texttt{Credential} and \texttt{Password} in \citefig{meta-model}.
\texttt{Credential} is used to authenticate her to supported providers through \texttt{Connector}.
The \texttt{Connector} is a common interface against supported providers.
This component of CloudML is directly associated with \citereq{multicloud}.
\texttt{Credential} is in this case in the form of an \texttt{Access Key ID} (random GUID),
but with other providers it might be in another form, \eg a username for Rackspace.
Although the form is different, the physical object type (String) is the same.

\subsection{Single node topology}

Initially she is using the topology shown in~\citefig{singlenode}.
This topology introduces a single node, which hosts every tier of the application.
This is not an uncommon topology for development purposes.

\paragraph{Topology considerations.}

Alice establishes a \emph{single-node} based topology, as seen in \citefig{singlenode}.
Since this single node handles both computation and storage, 
Alice decides to increase capabilities of both processing (number of \texttt{Cores}) and 
\texttt{Disk} size on the \texttt{Node}.
Both of these attributes are incremented because the instance hosts
the main application as well as the database.

The approach of using one single node is good in terms of simplicity,
since all important components of the application are located in one single place.
Other advantages distinguish themselves as well, such as network connections where
the address of other components are determined to be ``this computer'' (\emph{localhost}).

\paragraph{Building templates.}

In the end Alice inserts all data about topologies into a \texttt{Template}. 
The template include physical descriptions of the \texttt{Node},
and a list of the type \texttt{Property} for the node.
The \texttt{Node} has a \texttt{name} used to reference the node under provisioning.
The properties the node can have are configurations of attributes on a set of given capabilities.
These configurations are what define what type of tasks a node is suitable for.
In Alice's case the node has increased two important attributes to support both higher computation 
demand and storage capabilities, \ie $2$ cores and $2000$ \myac{GB}
\footnote{
  Size is expressed in \myac{GB}, but measurement can change depending on implementation of \citereq{software-reuse}.
}
in hard drive size.
By not altering any other attributes on the respective nodes, they will be set to minimal values.
This is a positive expectation, since the nodes will handle specific tasks, which does not 
demand enhancing of other attributes.

\paragraph{Provisioning.}
\input{figs/sequence-singlenode}
\input{figs/scenario1}

With these models Alice initializes provisioning by calling 
\texttt{build} on \texttt{CloudMLEngine}, providing \texttt{Credential} and \texttt{Template}.
This starts the asynchronous job of configuring and creating 
\texttt{Instances} based on \texttt{Nodes}.
In \citefig{scenario1-1} an object diagram describe the initial configuration at runtime,
after CloudML has interpreted the template files.
The instance produced by the template and node is in the form of a single object,
as represented by the object diagram in \citefig{scenario1-2}.
\texttt{Instance} only refer to template by a \emph{String}, \texttt{templateName}.
This is semantically correct because the template is a transparent entity
in the context of provisioning, and is only used as a reference.
\texttt{Instance} is also an \emph{internal} element in CloudML, and might not 
have to be indirectly or directly exposed to end users.

\texttt{RuntimeInstance} is specifically designed to complement \texttt{Node} with \texttt{RuntimeProperties},
as \texttt{Properties} from \texttt{Node} still contain valid data.
When \texttt{CloudMLEngine} start provisioning, a \texttt{RuntimeInstance} is created immediately,
and returned to Alice.
These are \myac{M@RT} within CloudML, designed to provide asynchronous provisioning
according to \citereq{m@rt}.
They are reflections of \texttt{Instance}, and they aggregate instances.

The method call to \texttt{build} is described in \citefig{sequence-singlenode}.
In this figure \texttt{RuntimeInstance} is returned directly to Alice,
because these are asynchronous elements within CloudML, which end users can gather 
information through.
This is emphasized within \citefig{sequence-singlenode} through \texttt{getStatus} method calls.
\texttt{Instance} is never visualized, this is because it is an internal format
within CloudML and does not need to be presented in the sequence diagram,

When the \texttt{Node} is provisioned successfully and sufficient meta-data is gathered,
Alice can start the deployment.
CloudML has then completed its scoped task of provisioning.

\subsection{Three nodes topology}

For scalability and modularity the \emph{single-node} approach is restraining,
\ie it does not scale very well, and does not benefit from cloud advantages.
If the application consumes too much \myac{CPU} power, 
this slows the application totality down and decreases usability.
There is no strong link between CloudML and the application, but to maintain
scalability some measures must be manually developed into \emph{BankManager}.
So the initial application code includes support for work load distribution through 
application design and deployment considerations.
In \emph{BankManager} these measures consists of manually setting 
physical database address before deploying the application.

In the described scenario, Alice provision \emph{BankManager} to one single instance on \myac{AWS}.
In many cases this setup is sufficient, but major advantages
could be gained through the opportunity of horizontal scalability (\emph{scale out}).
There are distinct benefits to this.
If Alice deployed an application that should suddenly, 
rapidly and unexpectedly gain popularity, her current setup (one single node) might not be sufficient.
In case of such event Alice should change her topology from her initial one seen in 
\citefig{singlenode} with one node, to that of \citefig{threenodes} with three nodes.
Or even the topology seen in \citefig{frontends}, with ``unlimited'' amount of nodes.
This topology is more advanced and utilizes the cloud on a higher level.
It has three nodes, two for the application logic (front-end) and one for the database (back-end).
In front it has a \emph{load balancer}, which is a cloud service ensuring that requests
are spread between front-end nodes based on predefined rules.
Even though this service is meant for balancing requests to front-ends,
it can actually be used internally in between local nodes as well.

\paragraph{New template.}

Alice changes her topology by editing her existing \texttt{Template} 
to contain three nodes instead of one. 
She also changes the node attributes to suite their new needs better,
\ie increasing amount of \texttt{Cores} on front-end, and increased \texttt{Disk} for back-end \texttt{Node}.
The characteristics Alice choose for her \texttt{Nodes} and \texttt{Properties} are fitted
for the chosen topology.
All \texttt{Properties} are optional and thus Alice does not have to define them all.

\paragraph{Rebuild.}
\input{figs/sequence-threenodes}

Then she executes \texttt{build} on \texttt{CloudMLEngine} again,
which will provision the new nodes for her.
She will get three new nodes, and the previous provisioned nodes must be manually terminated.
More about this in \citechap{perspectives}.
The outline of how nodes are provisioned is shown in \citefig{sequence-threenodes-1}.
In the figure \texttt{RI} is an abbreviation of \texttt{RuntimeInstance}, to save space.
It is also split into three parts expressing different steps, 
\begin{ii}
  \iitem provisioning, 
  \iitem node communications and
  \iitem how a load balancer service is established.
\end{ii}
This figure is similar to \citefig{sequence-singlenode}, but with three nodes instead of one.
Both percept \iii{1} and \iii{2} are found in \citefig{sequence-singlenode}.
Another difference is that \texttt{User} does more calls to \texttt{CloudML},
which express how statuses between \texttt{RI}s are updating.

When connecting front-end instances of \emph{BankManager} to back-end instances Alice must 
be aware of the back-ends \texttt{PrivateIP} address, which she will retrieve from CloudML
during provisioning according to \myac{M@RT} approach.
This was not necessary for the initial scenario setup, but could still be applied
as good practice.

\paragraph{Three nodes summary.}
\input{figs/scenario2}

The benefits of a topology where the application is distributed over several nodes 
is the scalability and modularity, which were lacking in the \emph{single-node} topology.
For instance, if the user demand should rapidly increase, Alice could change her topology to
provision more front-end nodes as seen in \citefig{frontends}.
This could be done presumably without greater changes to origin application,
since the application is initially designed for such a distributed topology.

An object diagram of the topology is shown in \citefig{scenario2-1}.
There is nothing that concretely separate front-end nodes from back-end nodes,
this can only be determined from node \texttt{name} or what attributes are altered.
The separation is completely up to Alice when doing the deployment,
\ie nothing in CloudML will restrain or limit Alice 
when it comes to work load distribution between nodes.

As with the instances in \citefig{scenario1-2} the instances in \citefig{scenario2-2}
are reflections of the nodes (and template) in \citefig{scenario2-1}.
The template name is referenced within each \texttt{Instance} 
for the reasons mentioned earlier.

\subsection{Multicloud provisioning}
\input{figs/topology-multicloud}

Alice could later decide to use another provider, either as replacement or complement to her current setup,
because of availability, financial benefits or support.
To do this she must change the provider name in \texttt{Account} and call \texttt{build} on \texttt{CloudMLEngine} again,
this will result in an identical topological setup on a supported provider.
\texttt{UserLibrary} in \citefig{figs/meta-model} visualizes that \texttt{Account} and \texttt{Template} are 
physical parts maintainable by the user.

The \texttt{build} method support provisioning of several templates to one account (same provider).
There is also a constraint/limitation, a set of templates can not be simultaneously 
cross-deployed to different providers,
\ie not possible to define cross-provider (\emph{multicloud}) nodes in a single topology.
This is for the sake of tidiness, clarity and technical limitations.
CloudML support multicloud provisioning,
just that such functionality is achieved by sequential re-provisioning,
which will not retain a full multicloud deployment.

\paragraph{\myac{AWS} and Rackspace combined.}

To describe the layout of a multicloud provisioning with CloudML,
a scenario is invented and a complementary figure is crafted.
In the new scenario Alice creates a topology spanning over two providers,
as seen in \citefig{topology-multicloud}.
The first \ldots MORE TO COME!

\ie both \myac{AWS} and Rackspace.


\mysection{technological-assessments}{Technological assessments and considerations}

\subsection{Programming language and application environment.}

When considering \emph{programming language} and \emph{application environment} 
the important aspects are the ones mentioned in \citereq{foundation},
\begin{ii}
  \iitem ease of use,
  \iitem community size,
  \iitem closed/open source,
  \iitem business viability,
  \iitem modernity and 
  \iitem matureness.
\end{ii}
For the implementation to be a successful approach towards CloudML 
the aspects chosen must also be relevant for future improvements.
At the same time the aspects chosen must be appealing to existing communities of interest,
without this it will not gain the footing it needs.
The most important aspects are therefore precept \iii{2}, \iii{5} and \iii{6}.

\subsection{Asynchronous information gathering and distribution.}

\paragraph{The design.}

When a node is being propagated it changes type to 
\texttt{RuntimeInstance}, which can have a different \emph{state} such as 
\emph{Configuring}, \emph{Building}, \emph{Starting} and \emph{Started}.
Considerations for implementation will be described in \citesec{modules}.

When a \texttt{RuntimeInstance} reaches \emph{Starting} state the provider 
has guaranteed its existence, including the most necessary metadata.
When all nodes reaches this state the task of provisioning is concluded.

\paragraph{Patterns.}

Provisioning nodes is by its nature an asynchronous action that can take minutes to execute.
For CloudML to compensate with this asynchronous behavior several approaches could be made,
as mentioned in \citechap{requirements}, \ie observer pattern, command pattern, actor model,
or publish-subscribe pattern.
Patterns tightly bound to using an object-oriented language for \citereq{foundation}.
The core idea of integration and benefits of these approaches are:
\begin{description}
  \item[Observer pattern.] The essence of this pattern is a one-to-many distribution of events between objects.
    This can be explained with a restaurant as an example, with one chef and two waiters.
    The chef is an \emph{observable} and the two waiters are \emph{observers}.
    The chef does some work (cooking), and when he or she is complete with a dish all observers are notified.
    The observers receive this event and can act upon it, 
    \eg the first waiter ignores the dish, because it does not belong to any of his or her tables, 
    while the other waiter takes the dish to appropriate table.
  \item[Command pattern.] Is about encapsulating data and logic. 
    Implementations have a known method, \eg \emph{execute} which comes from an \emph{interface}.
    So logic could be transparent when invoking them.
    In the restaurant-example one can consider a general \emph{waiter} to be the interface,
    and the two waiters would each be separate implementations, 
    \eg \emph{TableAToC} and \emph{TableDToH}.
    When the chef \emph{invokes} the method \emph{execute} on any type of \emph{waiter}, 
    he or she does not need to know anything about their implementation, 
    each waiter will know by themselves which table to visit.
  \item[Actor model.] Solves the problem with asynchronous communication through passing messages
    in between \emph{actors}.
    These messages are decoupled from the sender, resulting in proper asynchronous communication.
    Actors can also create new actors.
    With the restaurant-example one can imagine all three elements, \ie chef, first and second waiter,
    to be individual actors.
    The chef must know about the first waiter, 
    but the waiters do not necessarily need to know about each other.
    When a meal is done the chef can inform the correct waiter (one associated with correct table).
    The benefit here is that the message is decoupled and asynchronous, so the chef can start
    working on the next meal without waiting for the waiter to return.
  \item[Publish-subscribe pattern.] This pattern is very similar to observer pattern in behavior,
    but is more focused on message distribution logic.
    Compared to observer pattern the \emph{observable} can be considered a \emph{publisher} and
    \emph{observers} can be called \emph{subscribers}.
    When a \emph{publisher} sends a message it does not send it directly to any receivers,
    instead there is a filter-based logic which selects receivers based on condition they set themselves.
    In the restaurant example, similar to that with observer pattern, the chef is \emph{publisher}
    and both waiters are \emph{subscribers}.
    When the chef completes a meal he or she notify the waiters based on their \emph{conditions},
    \eg the first waiter listen for events of type \emph{TableA}, \emph{TableB} and \emph{TableC}.
    If the finished meal was assigned for table $A$ the first waiter would get the message.
\end{description}
Of these solutions the most promising one is \emph{actor model} because it is more directly aimed
at solving asynchronous communication.
The other solutions can provide assistance by accommodating communications through events, 
but by them selves they do not solve the issue of slow provisioning.
An interesting approach is to combine the \emph{actor model} with one of the patterns.
By doing this the behavior functionality is combined with the asynchronous benefits within the actor model.
Of the previous mentioned patterns only \emph{observer} and \emph{publish-subscribe} patterns 
fit well with designed behavior of CloudML.
Of these \emph{publish-subscribe} is the most scalable and dynamic one (in runtime),
but also the most complicated.
When combining the \emph{actor model} with such pattern it is important to keep the implementation
as simple as possible, without withholding functionality.
Hence the best solution for CloudML is to combine \emph{actor model} with \emph{observer pattern}.

The \emph{actor model} can be implemented in many different ways, even on different tiers.
Both requirement \citereq{foundation} and \citereq{software-reuse} can assist with either
a built-in functionality in the language, environment or an external library or framework.
The observer pattern can be implemented in many ways,
\eg using \texttt{java.util.Observer} and \texttt{java.util.Observable}.

\subsection{Lexical format.}

Requirement \citereq{lexical-template} from \citechap{requirements} consists of two
important core elements.
The first is \emph{important aspect}, \ie functional demands the format must fulfill,
such as how popular it is and how well it is supported by programming languages.
Second element is that of \emph{data format}, \ie the actual language used to 
serialize data.
This last element is not important for design, and will be introduced and
further described in \citesec{technologies} (\citechap{implementation}).
The important aspects of a lexical format for CloudML are:
\begin{itemize}
  \item Renowned among software developer communities, industry and the academic domain.
    The language will be used directly by these parties, so it is beneficial
    that they are familiar with the syntax.
  \item Integrates (supporting libraries) with most common existing technologies.
    The range of \citereq{foundation} should not be limited by the format.
  \item Human-readable, to some extent.
    End users needs to create and edit these files, often by hand.
    Therefore it must be readable and manually maintainable.
  \item Function with web-services and web-based technologies.
    CloudML is a language designed for \emph{cloud environments},
    so choosing a format that works well on the web is crucial.
\end{itemize}
