\mychapter{design}{Analysis and design - CloudML}

In the previous chapter, \citechap{vision}, the core vision of CloudML was presented,
including descriptions of surrounding elements \ie, actors and topologies.
In this chapter the focus is narrowed down to the design of the implementation which
consitutes CloudML.

\section{Meta model}
\input{figs/meta-model}
In this section the meta model from CloudML will be presented.
The model is visualized in \citefig{meta-model}, and will be described through a specific scenario.
The scenario also describes the implementation design through how it is used.

\paragraph{Scenario introduction.}

CloudML is introduced by using a scenarios where ``Alice'' is provisioning the 
\emph{BankManager} application from \citechap{challenges} to \myac{AWS},
initially using the topology shown in~\citefig{singlenode}.
This topology introduces a single node which hosts every tier of the application.
This topology is not uncommon, but it does not scale very well, 
and does not benefit from cloud advantages.

It is compulsory that she possesses an \myac{AWS} account in advance of the scenario.
This is essential information needed for the scenario to be successful,
and since she is indirectly using \myac{AWS} \myac{API}s 
she must also have \emph{security credentials},
\ie, \emph{Access Key ID} and \emph{Secret Access Key}.

The roles, or actors, which Alice assumes in this scenario, regarding \citefig{big-picture},
are both \emph{cloud expert} and \emph{user}.
She will define the topologies, create the templates and use CloudML to provision her models.
In addition to these roles she is also partly \emph{application designer/developer}
because of tight coupling between running instances and application deployment.

\paragraph{Authentication.}

She associate Access Key ID and Secret Access Key with 
\texttt{Credential} and \texttt{Password} in \citefig{meta-model}.
\texttt{Credential} is used to authenticate her to supported providers through \texttt{Connector}.
The \texttt{Connector} is a common interface against supported providers.
This component of CloudML is directly associated with \citereq{multicloud}.
\texttt{Credential} is in this case in the form of an Access Key ID (random GUID),
but with other providers it might be in another form, \eg, a username for Rackspace.
Although the form is different, the physical object type (String) is the same.

\paragraph{Topology considerations.}

Alice establishes a \emph{single-node} based topology, as seen in~(\citefig{singlenode}).
Since this single node handles both computation and storage Alice decides to 
increase capabilities of both processing (number of \texttt{Cores}) and 
\texttt{Disk} size on the \texttt{Node}.
Both these attributes are incremented because the instance hosts
the main application as well as the database.
The characteristics Alice choose for her \texttt{Nodes} and \texttt{Properties} are fitted
for the chosen topology \eg, more computation power for \texttt{front-end} nodes and more disk for \texttt{back-end} nodes.
All \texttt{Properties} are optional and thus Alice does not have to define them all.

The approach of using one single node is good in terms of simplicity since all important
components of the application is located in one single place.
Other advantages can distinguish themselves as well, such as network connections where
the address of other components are determined to be localhost (\emph{this computer}).
But for scalability and modularity the \emph{single-node} approach is restraining.
\eg, if the application consumes too much \myac{CPU} power, 
this slows the application totality down and decrease usability.
There is no strong link between CloudML and the application, but to maintain
scalability some measurements must be manually developed into \emph{BankManager}.
So the initial application code includes support for work load distribution through 
application design and deployment considerations.

\paragraph{From templates to nodes.}

In the end Alice insert all data about topologies into a \emph{textual file} which describes the topology.
This file is a \texttt{Template}, and is referred to by \texttt{name}.
The template file include physical descriptions of \texttt{Node},
and a list of the type \texttt{Property} for each node.
Every \texttt{Node} has a \texttt{name} used to reference the node under provisioning.
The properties a node can have are configurations of attributes on a set of given capabilities.
These configurations are what define what type of tasks a node is suitable for.

\paragraph{Provisioning.}

With these models Alice initializes provisioning by calling 
\texttt{build} on \texttt{CloudMLEngine},
and this starts the asynchronous job of configuring and creating \texttt{Nodes}.
When connecting front-end instances of \emph{BankManager} to back-end instances Alice must 
be aware of the back-ends \texttt{PrivateIP} address, which she will retrieve from CloudML
during provisioning according to \emph{models@run.time}~(M@RT) approach.
\texttt{RuntimeInstance} is specifically designed to complement \texttt{Node} with \texttt{RuntimeProperties},
as \texttt{Properties} from \texttt{Node} still contain valid data.
When all \texttt{Nodes} are provisioned successfully and sufficient meta-data are gathered
Alice can start the deployment, CloudML has then completed its scoped task of provisioning.
Alice could later decide to use another provider, either as replacement or complement to her current setup,
because of availability, financial benefits or support.
To do this she must change the provider name in \texttt{Account} and call \texttt{build} on \texttt{CloudMLEngine} again,
this will result in an identical topological setup on a supported provider.

\hr

\paragraph{Scenario with three nodes.}
The second topology Alice will use is more advanced and utilizes the cloud on a higher level.
It has three nodes, two for the application logic (front-end) and one for the database.
In front it has a \emph{load balancer} which is a cloud service.
\hr

The second scenario is based on~\citefig{threenodes} with two more nodes than in the first scenario.
Alice models the appropriate \texttt{Template} consisting
of three \texttt{Nodes}.
By increasing amount of \texttt{Cores}, and increased \texttt{Disk} for back-end \texttt{Node}.
By not altering any other attributes on the respective nodes they will be set to default values.
This is an positive expectation, since the nodes will handle specific tasks which does not 
demand enhancing of other attributes.

The benefits of a topology where the application is distributed over several nodes 
is the scalability and modularity which were lacking in the \emph{single-node} topology.
\eg, if the user demand should rapidly increase Alice could change her topology to
provision more front-end nodes as seen in \citefig{frontends}.
This could be done presumably without greater changes to origin application,
since the application is initially designed for such a distributed topology.


\paragraph{Scenario played out.}
\input{figs/scenario1}
\input{figs/scenario2}

\texttt{CloudMLEngine} is the main entry point, it has the method \texttt{build}
which is used to initialize provisioning.
\texttt{Property} have four children but is designed to be extendable in case
new types of properties should be included. The same design principle
is applied to \texttt{RuntimeProp}.
\texttt{UserLibrary} visualizes that \texttt{Account} and \texttt{Template} are 
physical parts maintainable by the user.

\paragraph{And we saw?}

The mist during daytime.

\input{figs/sequencediagram}

\section{Technological assessments}

\paragraph{Programming language and .}

For \emph{programming language} and \emph{application environment} the following were considered.
\begin{ii}
  \iitem JavaScript (Node.js) [\todo{Need source? Got 2 articles}],
  \iitem Java (JDK),
  \iitem Scala (JDK),
  \todo{
    \iitem Python and
    \iitem C\# (.NET).
  }
\end{ii}
Preceding \iii{2} to \iii{5} are well-known languages and environments recognized by both the enterprise world as well as the academic world.
Preceding \iii{1} is a newer and more unknown type of technology which has yet to 
make a large footprint in the two worlds. 
It is based on the \myac{JIT}-powered JavaScript engine V8 created by Google and follow a 
CommonJS-based module pattern over an event-driven architecture.
Preceding \iii{1} were brought in as an consideration because of the abilities to operate
with \myac{JSON}, its aim at web development on the cloud and the modernity.

\section{Asynchronous information harvesting}

Provisioning nodes is by its nature an asynchronous action that can take minutes to execute.
For CloudML to achieve this asynchronous behavior several approaches could be made,
as mentioned in \citechap{requirements}, \eg, command pattern, aspect-oriented programming,
or publish-subscribe pattern.

When a node is being propagated it changes type to \texttt{RuntimeInstance}, 
which can have a different \emph{states} such as \emph{Configuring}, \emph{Building}, \emph{Starting} and \emph{Started}.
When a \texttt{RuntimeInstance} reaches \emph{Starting} state the provider has guaranteed its existence, including
the most necessary metadata, when all nodes reaches this state the task of provisioning is concluded.

\hr 

\todo{Read over, copied from old vision} \\
In this chapter the core approach and steps on the research to implementing CloudML will be described.
In the previous chapters, \citechap{challenges} and \citechap{requirements}, 
challenges and requirements were identified and described.
In this part of the thesis (\emph{contribution}) the challenges will be addressed 
by applying and implementing the requirements.

There are four main steps from start of the problem to an functional implementation.
\begin{enumerate}
  \item Identify and research in \emph{state of the art}.
  \item Recognize \emph{challenges}.
  \item Determine \emph{requirements} based on \emph{challenges}.
  \item \emph{Analyze} solutions, tools and procedure to implement \emph{requirements}.
  \item \emph{Implement} a solution based on \emph{analyzed} results.
\end{enumerate}
Of these steps step $1$ (one) to $3$ (three) are already covered by \citechap{state-of-the-art}
, \citechap{challenges} and \citechap{requirements}.
This chapter is an intermediate chapter which will introduce the chapter of \citechap{design}
and \citechap{implementation}.

\todo{read over}

For the sake of tidiness, clarity and technical limitations it 
should not be possible to define cross-provider (\emph{multicloud}) nodes in a single topology.
This itself does not mean CloudML will not support multicloud provisioning,
instead such functionality is achieved by utilizing more than one template,
which will not retain a full multicloud deployment.
