\mychapter{design}{Analysis and design - CloudML}

In the previous chapter, \citechap{vision}, the core vision of CloudML was presented,
including descriptions of surrounding elements \ie, actors and topologies.
In this chapter the focus is narrowed down to the design of the implementation which
consitutes CloudML.

\section{Meta model}
\input{figs/architecture}
In this section the meta model from CloudML will be presented.
The model is visualized in \citefig{architecture}, and will be described through a specific scenario.

\paragraph{Scenario introduction.}

CloudML is introduced by using a scenarios where ``Alice'' is provisioning the 
\emph{BankManager} application from \citechap{challenges} to \myac{AWS},
initially using the topology shown in~\citefig{singlenode}.
This topology introduces a single node which will host every tier of the application.
This topology is not uncommon, but it does not scale very well, 
and does not benefit from cloud advantages.

It is compulsory that she possesses an \myac{AWS} account in advance of the scenario.
This is essential information needed for the scenario to be successful,
and since she will be indirectly using \myac{AWS} \myac{API}s 
she must also have \emph{security credentials},
\ie Access Key ID and Secret Access Key.

\paragraph{Authentication.}

She associate \emph{Access Key ID} and \emph{Secret Access Key} with 
\texttt{Credential} and \texttt{Password} in \citefig{architecture}.
\texttt{Credential} is used to authenticate her to supported providers through \texttt{Connector}.
\texttt{Connector} is a common interface against supported providers.
This component of CloudML is directly associated with \citereq{multicloud}.
\texttt{Credential} is in the form of an \emph{access key} (random GUID) or a username.
The characteristics Alice choose for her \texttt{Nodes} and \texttt{Properties} are fitted
for the chosen topology \eg, more computation power for \texttt{front-end} nodes and more disk for \texttt{back-end} nodes.
All \texttt{Properties} are optional and thus Alice does not have to define them all.

\paragraph{Scenario with one single node.}

The first scenario Alice want to establish is a single node based one~(\citefig{singlenode}).
Since this single node will handle both computation and storage Alice decides to 
increase capabilities of both processing (number of \texttt{Cores}) and 
\texttt{Disk} size on the \texttt{Node}.
Both these attributes are incremented because the instance will eventually host the main
application as well as the database.

The approach of using one single node is good in terms of simplicity since all important
components of the application is located in one single place.
Other advantages can distinguish themselves as well, such as network connections where
the address of other components are determined to be localhost (\emph{this computer}).
But for scalability and modularity the \emph{single-node} approach is restraining.
For instance if the database should eventually consume more space than the node can provide.
\eg, if the application consumes too much \myac{CPU} power, 
this will slow the application totality down and decrease usability.
Measures must be set to support distributing work load, and for an initial setup this might not have been
included in application design and deployment considerations.

\paragraph{Scenario with three nodes.}

\hr
The second topology Alice will use is more advanced and utilizes the cloud on a higher level.
It has three nodes, two for the application logic (front-end) and one for the database.
In front it has a \emph{load balancer} which is a cloud service.
\hr

The second scenario is based on~\citefig{threenodes} with two more nodes than in the first scenario.
Alice models the appropriate \texttt{Template} consisting
of three \texttt{Nodes}.
By increasing amount of \texttt{Cores}, and increased \texttt{Disk} for back-end \texttt{Node}.
By not altering any other attributes on the respective nodes they will be set to default values.
This is an positive expectation, since the nodes will handle specific tasks which does not 
demand enhancing of other attributes.

The benefits of a topology where the application is distributed over several nodes 
is the scalability and modularity which were lacking in the \emph{single-node} topology.
\eg, if the user demand should rapidly increase Alice could change her topology to
provision more front-end nodes as seen in \citefig{frontends}.
This could be done presumably without greater changes to origin application,
since the application is initially designed for such a distributed topology.

\paragraph{General provisioning.}

With these models Alice can initialize provisioning by calling 
\texttt{build} on \texttt{CloudMLEngine},
and this will start the asynchronous job of configuring and creating \texttt{Nodes}.
When connecting front-end instances of \emph{BankManager} to back-end instances Alice must 
be aware of the back-ends \texttt{PrivateIP} address, which she will retrieve from CloudML
during provisioning according to \emph{models@run.time}~(M@RT) approach.
\texttt{RuntimeInstance} is specifically designed to complement \texttt{Node} with \texttt{RuntimeProperties},
as \texttt{Properties} from \texttt{Node} still contain valid data.
When all \texttt{Nodes} are provisioned successfully and sufficient metadata are gathered
Alice can start the deployment, CloudML has then completed its scoped task of provisioning.
Alice could later decide to use another provider, either as replacement or complement to her current setup,
because of availability, financial benefits or support.
To do this she must change the provider name in \texttt{Account} and call \texttt{build} on \texttt{CloudMLEngine} again,
this will result in an identical topological setup on a supported provider.

\paragraph{Scenario played out.}
\input{figs/scenario1}
\input{figs/scenario2}

\texttt{CloudMLEngine} is the main entry point, it has the method \texttt{build}
which is used to initialize provisioning.
\texttt{Property} have four children but is designed to be extendable in case
new types of properties should be included. The same design principle
is applied to \texttt{RuntimeProp}.
\texttt{UserLibrary} visualizes that \texttt{Account} and \texttt{Template} are 
physical parts maintainable by the user.

\paragraph{And we saw?}

The mist during daytime.

\input{figs/sequencediagram}

\section{Technological assessments}

\paragraph{Programming language and .}

For \emph{programming language} and \emph{application environment} the following were considered.
\begin{ii}
  \iitem JavaScript (Node.js) [\todo{Need source? Got 2 articles}],
  \iitem Java (JDK),
  \iitem Scala (JDK),
  \todo{
    \iitem Python and
    \iitem C\# (.NET).
  }
\end{ii}
Preceding \iii{2} to \iii{5} are well-known languages and environments recognized by both the enterprise world as well as the academic world.
Preceding \iii{1} is a newer and more unknown type of technology which has yet to 
make a large footprint in the two worlds. 
It is based on the \myac{JIT}-powered JavaScript engine V8 created by Google and follow a 
CommonJS-based module pattern over an event-driven architecture.
Preceding \iii{1} were brought in as an consideration because of the abilities to operate
with \myac{JSON}, its aim at web development on the cloud and the modernity.

\section{Asynchronous information harvesting}

Provisioning nodes is by its nature an asynchronous action that can take minutes to execute.
For CloudML to achieve this asynchronous behavior several approaches could be made,
as mentioned in \citechap{requirements}, \eg, command pattern, aspect-oriented programming,
or publish-subscribe pattern.

When a node is being propagated it changes type to \texttt{RuntimeInstance}, 
which can have a different \emph{states} such as \emph{Configuring}, \emph{Building}, \emph{Starting} and \emph{Started}.
When a \texttt{RuntimeInstance} reaches \emph{Starting} state the provider has guaranteed its existence, including
the most necessary metadata, when all nodes reaches this state the task of provisioning is concluded.

\hr 

\todo{Read over, copied from old vision} \\
In this chapter the core approach and steps on the research to implementing CloudML will be described.
In the previous chapters, \citechap{challenges} and \citechap{requirements}, 
challenges and requirements were identified and described.
In this part of the thesis (\emph{contribution}) the challenges will be addressed 
by applying and implementing the requirements.

There are four main steps from start of the problem to an functional implementation.
\begin{enumerate}
  \item Identify and research in \emph{state of the art}.
  \item Recognize \emph{challenges}.
  \item Determine \emph{requirements} based on \emph{challenges}.
  \item \emph{Analyze} solutions, tools and procedure to implement \emph{requirements}.
  \item \emph{Implement} a solution based on \emph{analyzed} results.
\end{enumerate}
Of these steps step $1$ (one) to $3$ (three) are already covered by \citechap{state-of-the-art}
, \citechap{challenges} and \citechap{requirements}.
This chapter is an intermediate chapter which will introduce the chapter of \citechap{design}
and \citechap{implementation}.

\todo{read over}

For the sake of tidiness, clarity and technical limitations it 
should not be possible to define cross-provider (\emph{multicloud}) nodes in a single topology.
This itself does not mean CloudML will not support multicloud provisioning,
instead such functionality is achieved by utilizing more than one template,
which will not retain a full multicloud deployment.
