\mychapter{design}{Analysis and design - CloudML}

In the previous chapter, \citechap{vision}, the core vision of CloudML was presented,
including descriptions of surrounding elements \eg, actors and topologies.
In this chapter the focus is narrowed down to the design and considerations 
of the implementation which constitutes CloudML.

\section{Meta model}
\input{figs/meta-model}
In this section the meta model from CloudML will be presented.
The model is visualized in \citefig{meta-model}, and will be described through a specific scenario.
The scenario also describes the implementation design through how it is used.

\paragraph{Scenario introduction.}

CloudML is introduced by using a scenarios where ``Alice'' is provisioning the 
\emph{BankManager} application from \citechap{challenges} to \myac{AWS},
initially using the topology shown in~\citefig{singlenode}.
This topology introduces a single node which hosts every tier of the application.
This topology is not uncommon, but it does not scale very well, 
and does not benefit from cloud advantages.

It is compulsory that she possesses an \myac{AWS} account in advance of the scenario.
This is essential information needed for the scenario to be successful,
and since she is indirectly using \myac{AWS} \myac{API}s 
she must also have \emph{security credentials},
\ie, \emph{Access Key ID} and \emph{Secret Access Key}.

The roles, or actors, which Alice assumes in this scenario, regarding \citefig{big-picture},
are both \emph{cloud expert} and \emph{user}.
She will define the topologies, create the templates and use CloudML to provision her models.
In addition to these roles she is also partly \emph{application designer/developer}
because of tight coupling between running instances and application deployment.

\paragraph{Authentication.}

She associate Access Key ID and Secret Access Key with 
\texttt{Credential} and \texttt{Password} in \citefig{meta-model}.
\texttt{Credential} is used to authenticate her to supported providers through \texttt{Connector}.
The \texttt{Connector} is a common interface against supported providers.
This component of CloudML is directly associated with \citereq{multicloud}.
\texttt{Credential} is in this case in the form of an Access Key ID (random GUID),
but with other providers it might be in another form, \eg, a username for Rackspace.
Although the form is different, the physical object type (String) is the same.

\paragraph{Topology considerations.}

Alice establishes a \emph{single-node} based topology, as seen in~(\citefig{singlenode}).
Since this single node handles both computation and storage Alice decides to 
increase capabilities of both processing (number of \texttt{Cores}) and 
\texttt{Disk} size on the \texttt{Node}.
Both these attributes are incremented because the instance hosts
the main application as well as the database.
The characteristics Alice choose for her \texttt{Nodes} and \texttt{Properties} are fitted
for the chosen topology \eg, more computation power for 
\emph{front-end} nodes and more disk for \emph{back-end} nodes.
All \texttt{Properties} are optional and thus Alice does not have to define them all.

The approach of using one single node is good in terms of simplicity since all important
components of the application is located in one single place.
Other advantages can distinguish themselves as well, such as network connections where
the address of other components are determined to be localhost (\emph{this computer}).
But for scalability and modularity the \emph{single-node} approach is restraining.
\eg, if the application consumes too much \myac{CPU} power, 
this slows the application totality down and decrease usability.
There is no strong link between CloudML and the application, but to maintain
scalability some measurements must be manually developed into \emph{BankManager}.
So the initial application code includes support for work load distribution through 
application design and deployment considerations.

\paragraph{From templates to nodes.}

In the end Alice insert all data about topologies into a \emph{textual file} which describes the topology.
This file is a \texttt{Template}, and is referred to by \texttt{name}.
The template file include physical descriptions of \texttt{Node},
and a list of the type \texttt{Property} for each node.
Every \texttt{Node} has a \texttt{name} used to reference the node under provisioning.
The properties a node can have are configurations of attributes on a set of given capabilities.
These configurations are what define what type of tasks a node is suitable for.

\paragraph{Provisioning.}
\input{figs/scenario1}

With these models Alice initializes provisioning by calling 
\texttt{build} on \texttt{CloudMLEngine}, providing \texttt{Credential} and \texttt{Template}.
This starts the asynchronous job of configuring and creating 
\texttt{Instances} based on \texttt{Nodes}.
In \citefig{scenario1-1} an object diagram describe the initial configuration at runtime,
after CloudML has interpreted the template files.
As mentioned, the node has increased two important attributes to support both higher computation 
demand and storage capabilities. \ie, $2$ cores and $2000$ in disk size 
(\myac{GB} respectively, but measurement can change depending on implementation of \citereq{software-reuse}).
By not altering any other attributes on the respective nodes they will be set to default values.
This is an positive expectation, since the nodes will handle specific tasks which does not 
demand enhancing of other attributes.
The Instance produced by the template and node is in the form of a single object,
as represented by the object diagram in \citefig{scenario1-2}.
Noticeable, \texttt{Instance} only refer to template by a \emph{String}, \texttt{templateName}.
This is semantically correct because the template is a transparent entity
in the context of provisioning, and is only used as a reference.

The \texttt{build} method support provisioning of several templates to one account (same provider),
but in this scenario that is not utilized.
There is also a constraint/limitation, a set of templates can not be simultaneously 
cross-deployed to different providers,
\ie, not possible to define cross-provider (\emph{multicloud}) nodes in a single topology.
This is for the sake of tidiness, clarity and technical limitations.
CloudML will support multicloud provisioning,
just that such functionality is achieved by sequential re-provisioning 
which will not retain a full multicloud deployment.

\texttt{RuntimeInstance} is specifically designed to complement \texttt{Node} with \texttt{RuntimeProperties},
as \texttt{Properties} from \texttt{Node} still contain valid data.
When \texttt{CloudMLEngine} start provisioning a set of \texttt{RuntimeInstances} are created immediately 
and returned to Alice.
These are models@run.time within CloudML, designed to provide asynchronous provisioning,
which will treat with \citereq{m@rt}.
They are reflections of \texttt{Instance}, and they aggregate instances.

When all \texttt{Nodes} are provisioned successfully and sufficient meta-data are gathered
Alice can start the deployment, CloudML has then completed its scoped task of provisioning.
Alice could later decide to use another provider, either as replacement or complement to her current setup,
because of availability, financial benefits or support.
To do this she must change the provider name in \texttt{Account} and call \texttt{build} on \texttt{CloudMLEngine} again,
this will result in an identical topological setup on a supported provider.
\texttt{UserLibrary} visualizes that \texttt{Account} and \texttt{Template} are 
physical parts maintainable by the user.

The method call to \texttt{build} is described in \citefig{sequencediagram}.
In this figure \texttt{RuntimeInstance} is returned directly to Alice,
because these are asynchronous elements within CloudML which end users can gather 
information through.
This is empathized within \citefig{sequencediagram} through \texttt{getStatus} method calls.
\texttt{Instance} is never visualized, this is because it is an internal format
within CloudML and does not need to be presented in the sequence diagram,

\paragraph{Unanticipated scalability needs.}

In the described scenario Alice provision \emph{BankManager} to one single instance on \myac{AWS}.
In many cases this setup is sufficient, but major advantages
could be gained through the opportunity of horizontal scalability (\emph{scale out}).
There are many benefits to this, 
\eg, if Alice deployed an application which should suddenly, 
rapidly and unexpectedly gain popularity her current setup (one single node) might not be sufficient.
In case of such event Alice should change her topology from the one seen in 
\citefig{singlenode} with one node, to that of \citefig{threenodes} with three nodes,
or even \citefig{frontends} with ``unlimited'' amount of nodes.
This topology is more advanced and utilizes the cloud on a higher level.
It has three nodes, two for the application logic (front-end) and one for the database (back-end).
In front it has a \emph{load balancer} which is a cloud service ensuring that requests
are spread between front-end nodes based on predefined rules.

Alice changes her topology by editing her existing \texttt{Template} files 
to contain three nodes instead of one. 
She also changes the node attributes to suite their new needs better,
\ie, increasing amount of \texttt{Cores}, and increased \texttt{Disk} for back-end \texttt{Node}.
Then she executes \texttt{build} on \texttt{CloudMLEngine} again,
which will provision the new nodes for her.
She will get three new nodes, and the previous provisioned nodes must be manually terminated.
More about this in \citechap{perspectives}.

When connecting front-end instances of \emph{BankManager} to back-end instances Alice must 
be aware of the back-ends \texttt{PrivateIP} address, which she will retrieve from CloudML
during provisioning according to \emph{models@run.time}~(M@RT) approach.
This was not necessary for the initial scenario setup, but could still be applied
as good practice.

\paragraph{Three nodes summary.}
\input{figs/scenario2}

The benefits of a topology where the application is distributed over several nodes 
is the scalability and modularity which were lacking in the \emph{single-node} topology.
\eg, if the user demand should rapidly increase Alice could change her topology to
provision more front-end nodes as seen in \citefig{frontends}.
This could be done presumably without greater changes to origin application,
since the application is initially designed for such a distributed topology.

An object diagram of the topology is shown in \citefig{scenario2-1}.
It is similar to the object diagram from \citefig{scenario1-1},
but there are three nodes instead of one, and the attributes are divided between them.
There is nothing which concretely separate front-end nodes from back-end nodes,
this can only be determined from node \texttt{name} or what attributes are altered.
The separation is completely up to Alice when doing the deployment,
\ie, nothing in CloudML will restrain or limit Alice 
when it comes to work distribution between nodes.

As with the instances in \citefig{scenario1-2} the instances in \citefig{scenario2-2}
are reflections of the nodes (and template) in \citefig{scenario2-1}.
The template name is referenced within each \texttt{Instance} 
for the reasons mentioned earlier.

\section{Technological assessments and considerations}

\input{figs/sequencediagram}

\paragraph{Programming language and application environment.}

When considering \emph{programming language} and \emph{application environment} 
the important aspects were the ones mentioned in \citereq{foundation},
\begin{ii}
  \iitem ease of use,
  \iitem community size,
  \iitem closed/open source,
  \iitem business viability,
  \iitem modernity and 
  \iitem matureness.
\end{ii}
For the implementation to be a successful approach towards CloudML 
the aspects chosen must also be relevant for future improvements.
At the same time the aspects chosen must be appealing to existing communities of interest,
without this it will not gain the footing it needs.
The most important aspects are precept \iii{2}, \iii{5} and \iii{6}.

Programming languages and environment considered were:
\begin{description}
  \item[Java (\myac{JVM})] Well known and recognized in both the enterprise domain, as well as the academic world.
    Support object-oriented programming and a vast amount of libraries are supported by the \myac{JVM}.
  \item[JavaScript (Node.js)] A newer and more unknown type of technology which has yet to 
    make a large footprint in the two domains. 
    It is based on the \myac{JIT}-powered JavaScript engine V8 created by Google and follow a 
    CommonJS-based module pattern over an event-driven architecture.
  \item[Scala (\myac{JVM})] Same environment as Java, but a more modern language focus and support on both 
    object-oriented programming and functional programming.
    This language is gaining popularity among both the academic and enterprise domain.
    Libraries supported by Java are also supported by Scala.
  \item[Python] well known in the academic world. Also follows both object-oriented and functional programming as
    Scala.
  \item[C\# (.NET)] Language and environment by Microsoft.
\end{description}
Languages in the previous list are introduced by their overall popularity.
Some where introduces despite this, such as \emph{Node.js}, 
which were brought in as an consideration because of the abilities to operate
with \myac{JSON}, its aim at web development on the cloud and the modernity.

\paragraph{Asynchronous information gathering and distribution.}

\subparagraph{The design.}

When a node is being propagated it changes type to \texttt{RuntimeInstance}, 
which can have a different \emph{state} such as 
\emph{Configuring}, \emph{Building}, \emph{Starting} and \emph{Started}.
The states are updated asynchronously, and can either be 
\emph{observed}, \emph{polled} or do \emph{push} itself based on the type of implementation.
Considerations for implementation will be described later.

When a \texttt{RuntimeInstance} reaches \emph{Starting} state the provider 
has guaranteed its existence, including the most necessary metadata.
When all nodes reaches this state the task of provisioning is concluded.

\subparagraph{Implementation considerations.}

Provisioning nodes is by its nature an asynchronous action that can take minutes to execute.
For CloudML to compensate with this asynchronous behavior several approaches could be made,
as mentioned in \citechap{requirements}, \eg, command pattern, actor model,
or publish-subscribe pattern.
The core idea of integration and benefits of these approaches are:
\begin{description}
  \item[Command pattern] Simple and well known design pattern. 
    This is tightly bound to using an object-oriented language for \citereq{foundation}.
  \item[Actor model] Solve the problem with asynchronous communication through passing messages.
  \item[Publish-subscribe pattern] Messages are distributed through \emph{events}.
    This solution expects some network communication.
\end{description}
Of these solutions the most promising one is \emph{Actor model} because it is more directly aimed
at solving asynchronous communication.
The other solutions can provide assistance by accommodating communications through events, 
but by them selves they do not solve the issue of slow provisioning.
The actor model can be implemented in many different ways as well, even on different tiers.
Both requirement \citereq{foundation} and \citereq{software-reuse} can assist with either
a built-in functionality in the language, environment or an external library or framework.

